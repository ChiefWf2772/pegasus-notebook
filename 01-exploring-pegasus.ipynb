{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the Topology of Pegasus\n",
    "D-Wave's newest quantum computer, Advantage, introduces a quantum processing unit (QPU) with a new architecture: the Pegasus family of topologies. This notebook explains the Pegasus topology and demonstrates its enhanced performance over QPUs of the previous generation used in the DW-2000Q system. \n",
    "    \n",
    "1. [The Pegasus Advantage](#The-Pegasus-Advantage) shows the differences between the previous and new topologies and their usefulness.\n",
    "2. [Navigating the Topology](#Navigating-the-Topology) demonstrates Ocean tools that help you use this QPU.\n",
    "3. [Example Problem: RAN-K](#Example-Problem:-RAN-K) solves a hard problem on two generations of systems.\n",
    "\n",
    "This notebook should familiarize you with the new Pegasus topology and the tools to use it.\n",
    "\n",
    "<img src=\"images/anim.gif\" width=200x/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**New to Jupyter Notebooks?** JNs are divided into text or code cells. Pressing the **Run** button in the menu bar moves to the next cell. Code cells are marked by an \"In: \\[\\]\" to the left; when run, an asterisk displays until code completion: \"In: \\[\\*\\]\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Pegasus Advantage\n",
    "\n",
    "The crucial technological advance made between all previous generations of D-Wave quantum computers and the Advantage system is the new QPU architecture. \n",
    "\n",
    "The D-Wave QPU is a lattice of interconnected qubits. While some qubits connect to others via couplers, D-Wave QPUs are not fully connected. Instead, the qubits interconnect in an topology: Chimera for the 2000Q and Pegasus for the Advantage.\n",
    "\n",
    "This layout of the D-Wave QPU is critical to translating a QUBO or Ising objective function into a format that a D-Wave system can solve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minor-Embedding: Mapping a Problem to Qubits\n",
    "\n",
    "<div class=\"alert alert-warning\" role=\"alert\" style=\"margin: 10px\">Note: If you already understand how problems are mapped to the D-Wave system, please skip ahead to the next text cell..</div>\n",
    " \n",
    "D-Wave systems solve binary quadratic models (BQM), the Ising model traditionally used in statistical mechanics and its computer-science equivalent, the quadratic unconstrained binary optimization (QUBO) problem. Given $N$ variables $x_1,...,x_N$, where each variable $x_i$ can have binary values $0$ or $1$, the system finds assignments of values that minimize\n",
    "\n",
    "$\\sum_i^N q_ix_i + \\sum_{i<j}^N q_{i,j}x_i  x_j$,\n",
    "\n",
    "where $q_i$ and $q_{i,j}$ are configurable (linear and quadratic) coefficients. \n",
    "\n",
    "Such objective functions can be represented by graphs. A graph comprises a collection of nodes (representing variables) and the connections between them (edges). For example, the QUBO formulation of a Boolean AND, $x_1 x_2 - 2(x_1+x_2)z +3z$, is represented by the graph:\n",
    "\n",
    "<img src=\"images/embedding_and.png\" width=300x/>\n",
    "\n",
    "To formulate a problem for the D-Wave system is to program $q_i$ and $q_{i,j}$ so that assignments of $x_1,...,x_N$ also represent solutions to the problem. This requires that the problem graph be mapped to the QPU. [Minor embedding](#https://docs.ocean.dwavesys.com/en/stable/concepts/embedding.html#embedding-sdk) maps problem variables ($x_1, x_2, z$ for the AND gate) to the indexed qubits of the D-Wave QPU. On the D-Wave system, nodes are qubits and edges are couplers.\n",
    "\n",
    "Were qubits on a QPU fully connected, with every qubit coupled to every other qubit, you could simply map each problem variable to a qubit. But with sparser QPU topologies, a variable might be represented by a *chain* of two or more qubits. For example, the AND is represented by a $K_3$ fully connected graph, and that cannot be mapped directly to a Chimera topology. Instead, a chain of 2 qubits is used to represent a single variable. For example, a chain of qubit 0 and qubit 4 might represent variable $z$.\n",
    "\n",
    "<img src=\"images/embedding_chimera_and.png\" width=500x/>\n",
    "\n",
    "The strength of the coupler between qubits 0 and 4, which represents\n",
    "variable $z$, is set to correlate the qubits strongly, so that in most\n",
    "solutions they have a single value for $z$. \n",
    "\n",
    "One such minor-embedding on a D-Wave 2000Q is shown below using the Ocean software's [dwave-inspector](#https://docs.ocean.dwavesys.com/en/stable/docs_inspector/sdk_index.html) tool. The problem graph, shown on the left, is embedded in four qubits , shown on the right against a background of the Chimera topology. The variable highlighted in dark magenta is represented by two qubits, numbers 251 and 253 in this particular embedding.\n",
    "\n",
    "<img src=\"images/embedding_3var4qubits.png\" width=700x/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Pegasus topology enables the Advantage QPU to more than doubles the number of available qubits compared to the 2000Q, and the working graph is denser, meaning each qubit is coupled to a greater number of neighboring qubits. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Qubits\n",
    "This subsection shows ...\n",
    "\n",
    "Problem sizes that now fir such as clique embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dwave_networkx as dnx\n",
    "\n",
    "C = dnx.chimera_graph(16)\n",
    "P = dnx.pegasus_graph(16)\n",
    "\n",
    "print(\"A 2000Q QPU can have up to {} qubits, an Advantage {}.\".format(len(C.nodes), len(P.nodes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: move to bokeh to enable view controls\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(14,6))\n",
    "dnx.draw_chimera(C, ax=ax[0], node_size=5, node_color='g')\n",
    "dnx.draw_pegasus(P, ax=ax[1], node_size=5, node_color='b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intuitively, creating an extremely sparse problem should enabling you embed on the QPUs large numbers of variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import dimod \n",
    "\n",
    "def generate_ran1(variables, interactions, draw=True):\n",
    "    \n",
    "    G = nx.random_regular_graph(n=variables, d=interactions)\n",
    "    bqm = dimod.generators.random.ran_r(1, G)\n",
    "    \n",
    "    if draw:\n",
    "        plt.figure(figsize=(7, 7))\n",
    "        nx.draw_networkx(G, pos=nx.spring_layout(G), with_labels=False, node_size=25) \n",
    "        plt.show()\n",
    "            \n",
    "    return bqm\n",
    "\n",
    "bqm = generate_ran1(1024, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import minorminer\n",
    "\n",
    "def try_embedding(bqm, timeout=60, tries=2):\n",
    "    \n",
    "    max_len = {}\n",
    "    for topology in [('Chimera', C), ('Pegasus', P)]:\n",
    "        \n",
    "        embedding = minorminer.find_embedding(bqm.quadratic, \n",
    "                                          topology[1].edges, \n",
    "                                          timeout=timeout, \n",
    "                                          tries=tries)\n",
    "        if not embedding:\n",
    "            print(\"{}: failed to embed.\".format(topology[0]))\n",
    "        else:\n",
    "            max_len[topology[0]] = max([len(embedding[n]) for n in embedding])\n",
    "            print(\"{}: found embedding with longest chain of {} qubits.\".format(topology[0], max_len[topology[0]]))\n",
    "            \n",
    "    return max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions = 2\n",
    "problems = 2\n",
    "\n",
    "draw_problem = True  # Change to false to not display problem graphs \n",
    "\n",
    "for variables in [500, 1000, 2000]:\n",
    "        \n",
    "    for problem in range(problems):\n",
    "        \n",
    "        print(\"\\nProblem {} of {} for {} variables:\".format(problem + 1, \n",
    "                                                            problems, \n",
    "                                                            variables))\n",
    "        \n",
    "        bqm = generate_ran1(variables, interactions, draw_problem)\n",
    "        try_embedding(bqm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, more than the doubling of the number of qubits, the power of the Pegasus topology comes from its higher connectivity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Greater Connectivity\n",
    "\n",
    "Increase the problem connectivity from 2 to 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "interactions = 3\n",
    "problems = 2\n",
    "\n",
    "draw_problem = True  # Change to false to not display problem graphs \n",
    "\n",
    "row = []\n",
    "df_columns = [\"Variables\", \"Problem\", \"Longest Chain\"]\n",
    "\n",
    "for variables in [100, 200, 400, 800]:\n",
    "        \n",
    "    for problem in range(problems):\n",
    "        \n",
    "        print(\"\\nProblem {} of {} for {} variables:\".format(problem + 1, \n",
    "                                                            problems, \n",
    "                                                            variables))\n",
    "        \n",
    "        bqm = generate_ran1(variables, interactions, draw_problem)\n",
    "        \n",
    "        row.append([variables, problem, try_embedding(bqm)])\n",
    "\n",
    "results = pd.DataFrame(row, columns=df_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how quickly chain lengths even for such sparse problems. Next, increase problem density:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = 100\n",
    "problems = 2\n",
    "\n",
    "draw_problem = True  # Change to false to not display problem graphs \n",
    "\n",
    "row = []\n",
    "df_columns = [\"Interaction\", \"Problem\", \"Longest Chain\"]\n",
    "\n",
    "for interactions in range(2, 16, 2):\n",
    "        \n",
    "    for problem in range(problems):\n",
    "        \n",
    "        print(\"\\nProblem {} of {} for {} interactions:\".format(problem + 1, \n",
    "                                                            problems, \n",
    "                                                            interactions))\n",
    "        \n",
    "        bqm = generate_ran1(variables, interactions, draw_problem)\n",
    "        \n",
    "        row.append([interactions, problem, try_embedding(bqm)])\n",
    "\n",
    "results = pd.DataFrame(row, columns=df_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(results[\"Interaction\"], results[\"Longest Chain\"].apply(lambda x: x['Chimera']), 0.35, label='Chimera')\n",
    "rects2 = ax.bar(results[\"Interaction\"], results[\"Longest Chain\"].apply(lambda x: x['Pegasus']), 0.35, label='Pegasus')\n",
    "\n",
    "ax.set_ylabel('Longest Chain')\n",
    "ax.set_xlabel('Interactions')\n",
    "ax.set_title('Longest Chains for Each Topology')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By now two points should stand out: \n",
    "\n",
    "* Higher connectivity enables you to scale up the number of problem variables and density\n",
    "* Minor-embedding can take time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clique Embeddings\n",
    "Clique embeddings can be very useful. If you have an embedding for a $K_n$ graph, you can then use it for all minors of that graph. \n",
    "\n",
    "Note that if your problems are sparse, using a clique embedding can be very wasteful, needlessly restricting the number of variables you can scale up to. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single $K_{4,4}$ Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C1 = dnx.chimera_graph(1)\n",
    "P1 = dnx.pegasus_graph(2, node_list=[4, 5, 6, 7, 40, 41, 42, 43])\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(14,6))\n",
    "dnx.draw_chimera(C1, ax=ax[0], node_size=2000, with_labels=True, node_color='g')\n",
    "dnx.draw_pegasus(P1, ax=ax[1], node_size=2000, with_labels=True, node_color='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from dwave.embedding import *\n",
    "\n",
    "for variables in range(2, 7):\n",
    "    \n",
    "    try:\n",
    "        embedding = chimera.find_clique_embedding(variables, 1, target_edges=C1.edges)\n",
    "        print(\"Chimera: embedded {} variables with longest chain of {}.\".format(variables, max([len(chain) for chain in embedding.values()])))\n",
    "    except ValueError:\n",
    "        print(\"Chimera: embedding {} variables failed.\".format(variables))\n",
    "\n",
    "    try:\n",
    "        #embedding = pegasus.find_clique_embedding(variables, target_graph=P1)\n",
    "        embedding = minorminer.find_embedding(nx.complete_graph(variables), P1.edges)\n",
    "        print(\"Pegasus: embedded {} variables with longest chain of {}.\\n\".format(variables, max([len(chain) for chain in embedding.values()])))\n",
    "    except ValueError:\n",
    "        print(\"Pegasus: embedding {} variables failed.\\n\".format(variables))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are [dwave-inspector](#https://docs.ocean.dwavesys.com/en/stable/docs_inspector/sdk_index.html) images of a $K_{5,5}$ clique embedded in the Chimera topology and a $K_{6,6}$ clique embedded in the Pegasus topology:\n",
    "\n",
    "<img src=\"images/k_55_chimera.png\" width=400x/>\n",
    "\n",
    "<img src=\"images/k_66_pegasus.png\" width=400x/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Largest Cliques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a given maximum chain length, you can embed a clique of the following sizes in Pegasus and Chimera graphs: \n",
    "\n",
    "| Chain Length | 2 | 3  | 4  | 5  | 6  | 7  | 8  | 9  | 10 | 11 | 12 | 13 | 14 |\n",
    "|--------------|---|----|----|----|----|----|----|----|----|----|----|----|----|\n",
    "| Chimera      | 4 | 8  | 12 | 16 | 20 | 24 | 28 | 32 | 36 | 40 | 44 | 48 | 52 |\n",
    "| Pegasus      | 6 | 16 | 26 | 36 | 42 | 49 |    |    |    |    |    |    |    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navigating the Topology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ocean's [dwave_networkx](#https://docs.ocean.dwavesys.com/en/stable/docs_dnx/sdk_index.html) provides tools for helping you navigate QPU working graphs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Unit cells* are ...\n",
    "\n",
    "This code cell creates a single unit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import dwave_networkx as dnx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "C = dnx.chimera_graph(2)\n",
    "\n",
    "for i in range(1, 32, 4):\n",
    "    print(\"qubit {} has Chimera coordinates {}\".format(i, C.nodes(data=True)[i]['chimera_index']))\n",
    "    \n",
    "dnx.draw_chimera(C, with_labels=True, node_size=500, node_color='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ocean provides tools to translate between coordinates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = dnx.chimera_coordinates(2)\n",
    "\n",
    "i = 13\n",
    "print(\"qubit {} has Chimera coordinates {}\".format(i, coords.linear_to_chimera(i)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The figure below provides a helpful way to envision a recurring structure of the Pegasus topology, similar to the unit cells of Chimera: the division of\n",
    "internal couplings into $K_{4,4}$ bipartite graphs abstracted as three layers of\n",
    "Chimera lattices. In this abstraction, each qubit forms part, through its\n",
    "internal couplers, of a Chimera unit cell in one layer (translucent green square) while\n",
    "additionally coupling to four qubits of a unit cell in a second layer (translucent blue square)\n",
    "and two qubits each of two units cells in a third layer (translucent pink squares).\n",
    "\n",
    "<img src=\"images/pegasus_zlayered_unitcells.png\" width=400x/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = dnx.pegasus_graph(2)\n",
    "\n",
    "for i in range(2, 12):\n",
    "    print(\"qubit {} has Pegasus coordinates {}\".format(i, P.nodes(data=True)[i]['pegasus_index']))\n",
    "\n",
    "H = dnx.pegasus_graph(2, node_list=[node for node in range(2, 12)])\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8,8))\n",
    "dnx.draw_pegasus(P, ax=ax, with_labels=True, node_size=500, node_color='y')\n",
    "dnx.draw_pegasus(H, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Problem: RAN-K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solver Availability\n",
    "This subsection checks whether you have access to both generations of solvers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dwave.system.samplers import DWaveSampler\n",
    "from dwave.cloud.exceptions import *\n",
    "\n",
    "try:\n",
    "    qpu_advantage = DWaveSampler(solver={'topology__type': 'pegasus', 'qpu': True})\n",
    "    qpu_2000q = DWaveSampler(solver={'topology__type': 'chimera', 'qpu': True})\n",
    "    \n",
    "    qpus = {'advantage': qpu_advantage, '2000q': qpu_2000q}\n",
    "\n",
    "    print(\"Connected to Advantage {} and 2000Q {}.\".format(qpu_advantage.solver.id, qpu_2000q.solver.id))\n",
    "except SolverNotFoundError:\n",
    "    print(\"Currently a pair of solvers are unavailable for sections comparing QPU technologies. Try those examples later.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Problem: Graph Partitioning \n",
    "There a "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formulating the Problem\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "import random\n",
    "import networkx as nx\n",
    "\n",
    "num_clusters = 20\n",
    "clusters = [random.randint(2, 3) for x in range(num_clusters)]\n",
    "G = nx.random_partition_graph(sizes=clusters, p_in=0.2, p_out=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "graph_nodes = 10\n",
    "cluster_size = 3\n",
    "density = 0.5\n",
    "density_external = 0.05\n",
    "G = nx.planted_partition_graph(l=graph_nodes, k=cluster_size, p_in=density, p_out=density_external)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.LFR_benchmark_graph(n=40, \n",
    "                           tau1=5, \n",
    "                           tau2=4, \n",
    "                           mu=0.2, \n",
    "                           average_degree=3,  \n",
    "                           max_degree=5, \n",
    "                           min_community=10, \n",
    "                           max_community=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(7, 7))\n",
    "nx.draw_networkx(G, pos=nx.spring_layout(G)) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "import networkx as nx\n",
    "\n",
    "graph_nodes = 10\n",
    "G = nx.complete_graph(graph_nodes)\n",
    "\n",
    "density = 1\n",
    "gamma = 0.5*(0.5*graph_nodes*(graph_nodes - 1))*density\n",
    "chain_strength = gamma*graph_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "graph_nodes = 40\n",
    "density = 1\n",
    "G = nx.erdos_renyi_graph(n=graph_nodes, p=density)\n",
    "\n",
    "gamma = 0.5*(0.5*graph_nodes*(graph_nodes - 1))*density\n",
    "chain_strength = gamma*graph_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(7, 7))\n",
    "nx.draw_networkx(G, pos=nx.spring_layout(G)) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Ising Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "nodes = ['a', 'b', 'c']\n",
    "edges = [('a', 'b'), ('b', 'c')]\n",
    "\n",
    "h = {'a': 2, 'b': 0, 'c': -2}\n",
    "J = {edge: 1.5 for edge in edges}\n",
    "\n",
    "print(h, J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_embedding = {'advantage': {'a': [336], \n",
    "                                'b': [479, 321], \n",
    "                                'c': [524]},\n",
    "                 '2000q': {'a': [1445], 'b': [1447, 1443], 'c': [1441]}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dwave.system import FixedEmbeddingComposite\n",
    "samplers = {qpu: FixedEmbeddingComposite(qpus[qpu], best_embedding[qpu]) for qpu in qpus}\n",
    "\n",
    "samplesets = {}\n",
    "for qpu in qpus:  \n",
    "    samplesets[qpu] = samplers[qpu].sample_ising(h, J,\n",
    "                                           num_reads=num_reads, \n",
    "                                           auto_scale=True,\n",
    "                                           chain_strength=1.5)\n",
    "    \n",
    "    avg_breaks = 100*sum(samplesets[qpu].record.chain_break_fraction)/num_reads\n",
    "    print(\"Chain breaks for {} is {:.3f} percent.\".format(qpu, avg_breaks))\n",
    "    print(samplesets[qpu])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_ising(h, J, factor=1.0):\n",
    "    range_h = [min(h[key] for key in h.keys()), \n",
    "               max(h[key] for key in h.keys())]\n",
    "    range_J = [min(J[key] for key in J.keys()), \n",
    "               max(J[key] for key in J.keys())]\n",
    "    \n",
    "    scaling_h = max(range_h[0]/-1.0, range_h[1]/1.0)\n",
    "    scaling_J = max(range_J[0]/-1.0, range_J[1]/1.0)\n",
    "    scaling = max(scaling_h, scaling_J)\n",
    "    return dict((key, factor*h[key]/scaling) for key in h.keys()), dict((key, factor*J[key]/scaling) for key in J.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_scaled, J_scaled =  scaled_ising(h, J, factor=1.0)\n",
    "\n",
    "range_hs = [min(h_scaled[key] for key in h_scaled.keys()), \n",
    "               max(h_scaled[key] for key in h_scaled.keys())]\n",
    "range_Js = [min(J_scaled[key] for key in J_scaled.keys()), \n",
    "               max(J_scaled[key] for key in J_scaled.keys())]\n",
    "\n",
    "print(\"Range h {}\".format(range_hs))\n",
    "print(\"Range J {}\".format(range_Js))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dwave.embedding import embed_ising\n",
    "\n",
    "chain_strength_scaled = 0.75\n",
    "\n",
    "embedded_vals = {}\n",
    "for qpu in qpus: \n",
    "    embedded_vals[qpu] = embed_ising(h_scaled, \n",
    "                                          J_scaled, \n",
    "                                          best_embedding[qpu], \n",
    "                                          qpus[qpu].adjacency, \n",
    "                                          chain_strength=chain_strength_scaled)\n",
    "    \n",
    "    print(\"{} J: {}\".format(qpu, sorted(set(embedded_vals[qpu][1][key] \n",
    "                            for key in embedded_vals[qpu][1].keys()))))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 8))\n",
    "axis = 1\n",
    "for qpu_name, qpu in qpus.items(): \n",
    "    ax = \"ax\"+str(axis)\n",
    "    ax = plt.subplot(2, 1, axis)\n",
    "    ax.set_title(\"Sampler: \" + qpu_name)\n",
    "    ax.set_xlabel(\"--\")\n",
    "    ax.set_ylabel(\"J\")\n",
    "    ax.plot(range(len(embedded_vals[qpu_name][1])), embedded_vals[qpu_name][1].values(), 'bo')\n",
    "    axis += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplesets_embedded = {}\n",
    "for qpu in qpus:  \n",
    "    samplesets_embedded[qpu] = qpus[qpu].sample_ising(embedded_vals[qpu][0], \n",
    "                                           embedded_vals[qpu][1], \n",
    "                                           num_reads=num_reads,\n",
    "                                           answer_mode='histogram',\n",
    "                                           auto_scale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dwave.embedding import unembed_sampleset, chain_break_frequency\n",
    "\n",
    "samplesets = {}\n",
    "for qpu in qpus:  \n",
    "        \n",
    "    samplesets[qpu] = unembed_sampleset(target_sampleset=samplesets_embedded[qpu], \n",
    "                                        embedding=best_embedding[qpu], \n",
    "                                        source_bqm=dimod.BinaryQuadraticModel.from_ising(h, J), \n",
    "                                        chain_break_method=None, \n",
    "                                        chain_break_fraction=True, \n",
    "                                        return_embedding=True)\n",
    "    \n",
    "    avg_breaks = 100*sum(samplesets[qpu].record.chain_break_fraction)/num_reads\n",
    "    print(\"Chain breaks for {} is {:.3f} percent.\".format(qpu, avg_breaks))\n",
    "    print(samplesets[qpu])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph --> QUBO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "\n",
    "\n",
    "Q = defaultdict(int)\n",
    "\n",
    "# Fill in Q matrix\n",
    "for u, v in G.edges:\n",
    "    Q[(u,u)] += 1\n",
    "    Q[(v,v)] += 1\n",
    "    Q[(u,v)] += -2\n",
    "\n",
    "for i in G.nodes:\n",
    "    Q[(i,i)] += gamma*(1-len(G.nodes))\n",
    "\n",
    "for i, j in combinations(G.nodes, 2):\n",
    "    Q[(i,j)] += 2*gamma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitting for Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minor Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import minorminer\n",
    "import numpy as np\n",
    "\n",
    "embedding_tries = 1\n",
    "\n",
    "best_embedding = defaultdict(lambda: ({}, 1000))\n",
    "for qpu in qpus:\n",
    "    print(\"\\nFinding a good embedding for {}:\\n\".format(qpu))\n",
    "    for i in range(embedding_tries):\n",
    "        embedding = minorminer.find_embedding(Q.keys(), qpus[qpu].edgelist, timeout=60, tries=1)\n",
    "        if not embedding:\n",
    "            print(\"   Failed to find an embedding {}.\".format(i))\n",
    "        else:\n",
    "            chain_lengths = list(len(chain) for chain in embedding.values())\n",
    "            avg_chain = np.average(chain_lengths)\n",
    "            print(\"    Embedding {} chain lengths: {:.2f} average, {:.2f} std, {} max, {} min.\".\n",
    "                  format(i,\n",
    "                         avg_chain,\n",
    "                         np.std(chain_lengths),\n",
    "                         np.max(chain_lengths),\n",
    "                         np.min(chain_lengths)))\n",
    "            if avg_chain < best_embedding[qpu][1]:\n",
    "                best_embedding[qpu] = (embedding, avg_chain) \n",
    "    print(\"Best for {} has average length {}.\\n\".format(qpu, best_embedding[qpu][1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Virtual Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_qubo(Q, factor=1.0):\n",
    "    range_linear = [min(Q[key] for key in Q.keys() if key[0] == key[1]), \n",
    "                max(Q[key] for key in Q.keys() if key[0] == key[1])]\n",
    "    range_quadratic = [min(Q[key] for key in Q.keys() if key[0] != key[1]), \n",
    "                   max(Q[key] for key in Q.keys() if key[0] != key[1])]\n",
    "    \n",
    "    scaling_linear = max(range_linear[0]/-1.0, range_linear[1]/1.0)\n",
    "    scaling_quadratic = max(range_quadratic[0]/-1.0, range_quadratic[1]/1.0)\n",
    "    scaling = max(scaling_linear, scaling_quadratic)\n",
    "    return dict((key, factor*Q[key]/scaling) for key in Q.keys())\n",
    "\n",
    "for qpu in qpus:\n",
    "    print(\"Coupler strength range:\", qpus[qpu].properties['extended_j_range'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_reads = 1000\n",
    "t_anneal = 1\n",
    "vg_chain_strength = 1.0\n",
    "scaling = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dwave.system import VirtualGraphComposite\n",
    "\n",
    "samplers = {\"sampler_\" + str(qpu): VirtualGraphComposite(qpus[qpu], \n",
    "            best_embedding[qpu][0], \n",
    "            chain_strength=vg_chain_strength) \n",
    "            for qpu in qpus}\n",
    "\n",
    "samplesets = {}\n",
    "for qpu, sampler in samplers.items():  \n",
    "    samplesets[qpu] = sampler.sample_qubo(scaled_qubo(Q, scaling), \n",
    "                                          num_reads=num_reads, \n",
    "                                          annealing_time=t_anneal, \n",
    "                                          answer_mode='histogram', \n",
    "                                          apply_flux_bias_offsets=True)\n",
    "\n",
    "    partition = [sum(samplesets[qpu].first.sample.values()), graph_nodes - sum(samplesets[qpu].first.sample.values())]\n",
    "    avg_breaks = 100*sum(samplesets[qpu].record.chain_break_fraction)/num_reads\n",
    "    print(\"Partition for {} is {} with lowest energy {:.3f}.\".format(qpu, partition, samplesets[qpu].first.energy))\n",
    "    print(\"Chain breaks for {} is {:.3f} percent.\".format(qpu, avg_breaks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(6, 3*len(samplesets)))\n",
    "axis = 1\n",
    "for qpu, sampler in samplers.items(): \n",
    "    ax = \"ax\"+str(axis)\n",
    "    ax = plt.subplot(len(samplesets)+1, 1, axis)\n",
    "    ax.set_title(\"Sampler: \" + qpu)\n",
    "    ax.set_xlabel(\"Sample\")\n",
    "    ax.set_ylabel(\"Energy\")\n",
    "    ax.plot(range(len(samplesets[qpu])), samplesets[qpu].record.energy, 'bo')\n",
    "    axis += 1\n",
    "\n",
    "lowest = round(0.1*len(samplesets[\"sampler_2000q\"]))\n",
    "ax = \"ax\"+str(axis)\n",
    "ax = plt.subplot(len(samplesets)+1, 1, axis)\n",
    "ax.set_title(\"Delta Energy\")\n",
    "ax.set_xlabel(\"Sample\")\n",
    "ax.set_ylabel(\"Delta Energy\")\n",
    "ax.plot(range(lowest), samplesets[\"sampler_2000q\"].record.energy[0:lowest]-samplesets[\"sampler_advantage\"].record.energy[0:lowest], 'bo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vg_flux_on = samplesets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Direct Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dwave.embedding import embed_qubo\n",
    "embedded_Q = embed_qubo(Q_scaled, best_embedding['2000q'][0], qpus['2000q'].adjacency, chain_strength=1.0)\n",
    "embedded_Q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixed Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_strength = 4000\n",
    "t_anneal = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dwave.system import FixedEmbeddingComposite\n",
    "\n",
    "num_reads = 1000\n",
    "t_anneal = 200\n",
    "\n",
    "samplers = {\"sampler_\" + str(qpu): FixedEmbeddingComposite(qpus[qpu], best_embedding[qpu][0]) \n",
    "            for qpu in qpus}\n",
    "\n",
    "samplesets = {}\n",
    "for qpu, sampler in samplers.items():  \n",
    "    samplesets[qpu] = sampler.sample_qubo(Q, num_reads=num_reads, \n",
    "                                             chain_strength=chain_strength, \n",
    "                                             annealing_time=t_anneal, \n",
    "                                             answer_mode='histogram')\n",
    "\n",
    "    partition = [sum(samplesets[qpu].first.sample.values()), graph_nodes - sum(samplesets[qpu].first.sample.values())]\n",
    "    avg_breaks = 100*sum(samplesets[qpu].record.chain_break_fraction)/num_reads\n",
    "    print(\"Partition for {} is {} with lowest energy {:.3f}.\".format(qpu, partition, samplesets[qpu].first.energy))\n",
    "    print(\"Chain breaks for {} is {:.3f} percent.\".format(qpu, avg_breaks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(6, 3*len(samplesets)))\n",
    "axis = 1\n",
    "for qpu, sampler in samplers.items(): \n",
    "    ax = \"ax\"+str(axis)\n",
    "    ax = plt.subplot(len(samplesets)+1, 1, axis)\n",
    "    ax.set_title(\"Sampler: \" + qpu)\n",
    "    ax.set_xlabel(\"Sample\")\n",
    "    ax.set_ylabel(\"Energy\")\n",
    "    ax.plot(range(len(samplesets[qpu])), samplesets[qpu].record.energy, 'bo')\n",
    "    axis += 1\n",
    "\n",
    "lowest = round(0.1*len(samplesets[\"sampler_2000q\"]))\n",
    "ax = \"ax\"+str(axis)\n",
    "ax = plt.subplot(len(samplesets)+1, 1, axis)\n",
    "ax.set_title(\"Delta Energy\")\n",
    "ax.set_xlabel(\"Sample\")\n",
    "ax.set_ylabel(\"Delta Energy\")\n",
    "ax.plot(range(lowest), samplesets[\"sampler_2000q\"].record.energy[0:lowest]-samplesets[\"sampler_advantage\"].record.energy[0:lowest], 'bo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_strength = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dwave.system import EmbeddingComposite\n",
    "\n",
    "# Import the problem inspector to begin data capture\n",
    "import dwave.inspector\n",
    "\n",
    "num_reads = 1000\n",
    "\n",
    "samplers = {\"sampler_\" + str(qpu): EmbeddingComposite(qpus[qpu]) for qpu in qpus}\n",
    "\n",
    "samplesets = {}\n",
    "for qpu, sampler in samplers.items():  \n",
    "    samplesets[qpu] = sampler.sample_qubo(Q, num_reads=num_reads,\n",
    "                                             answer_mode='raw',\n",
    "                                             chain_strength=chain_strength)\n",
    "    \n",
    "    partition = [sum(samplesets[qpu].first.sample.values()), graph_nodes - sum(samplesets[qpu].first.sample.values())]\n",
    "    avg_breaks = 100*sum(samplesets[qpu].record.chain_break_fraction)/num_reads\n",
    "    print(\"Partition for {} is {} with lowest energy {:.3f}.\".format(qpu, partition, samplesets[qpu].first.energy))\n",
    "    print(\"Chain breaks for {} is {:.3f} percent.\".format(qpu, avg_breaks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(6, 3*len(samplesets)))\n",
    "axis = 1\n",
    "for qpu, sampler in samplers.items(): \n",
    "    ax = \"ax\"+str(axis)\n",
    "    ax = plt.subplot(len(samplesets)+1, 1, axis)\n",
    "    ax.set_title(\"Sampler: \" + qpu)\n",
    "    ax.set_xlabel(\"Sample\")\n",
    "    ax.set_ylabel(\"Energy\")\n",
    "    ax.plot(range(len(samplesets[qpu])), samplesets[qpu].record.energy, 'bo')\n",
    "    axis += 1\n",
    "\n",
    "lowest = round(0.1*len(samplesets[\"sampler_2000q\"]))\n",
    "ax = \"ax\"+str(axis)\n",
    "ax = plt.subplot(len(samplesets)+1, 1, axis)\n",
    "ax.set_title(\"Delta Energy\")\n",
    "ax.set_xlabel(\"Sample\")\n",
    "ax.set_ylabel(\"Delta Energy\")\n",
    "ax.plot(range(lowest), samplesets[\"sampler_2000q\"].record.energy[0:lowest]-samplesets[\"sampler_advantage\"].record.energy[0:lowest], 'bo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hamming Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def get_hamming_distance(x1, x2):    # x1, x2 are NumPy arrays\n",
    "    return np.sum(x1 != x2)\n",
    "\n",
    "def normalized_hamming_distance(sols):\n",
    "    sols = np.array(sols)\n",
    "    hd = np.true_divide(np.array([get_hamming_distance(x1, x2) for x1, x2 in zip(sols, sols[1:])]), np.shape(sols)[1])\n",
    "    return [hd, np.mean(hd)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplesets = {}\n",
    "for qpu, sampler in samplers.items():  \n",
    "    samplesets[qpu] = sampler.sample_qubo(Q, num_reads=num_reads, \n",
    "                                             chain_strength=chain_strength, \n",
    "                                             annealing_time=t_anneal, \n",
    "                                             answer_mode='raw')\n",
    "\n",
    "for sampler in samplers.keys():\n",
    "    print(\"Lowest energy for {} is {:.3f}.\".format(sampler, samplesets[sampler].first.energy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.draw import plot_hamming # To see helper functions, select Jupyter File Explorer View from the Online Learning page\n",
    "\n",
    "hamming_distance = {}\n",
    "for qpu, sampler in samplers.items():  \n",
    "    hamming_distance[qpu] = normalized_hamming_distance(samplesets[qpu].record.sample)\n",
    "\n",
    "print(\"QPU time used: {} microseconds.\".format(sum(samplesets[qpu].info['timing']['qpu_access_time'] for qpu in samplers)))\n",
    "plot_hamming(hamming_distance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BEST SUBMISSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(x for x in Q.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VERIFY QUBO\n",
    "from dwave.system import EmbeddingComposite\n",
    "\n",
    "chain_strength = 1000\n",
    "num_reads = 1000\n",
    "\n",
    "samplers = {\"sampler_\" + str(qpu): EmbeddingComposite(qpus[qpu]) for qpu in qpus}\n",
    "\n",
    "samplesets = {}\n",
    "for qpu, sampler in samplers.items():  \n",
    "    samplesets[qpu] = sampler.sample_qubo(Q, num_reads=num_reads, \n",
    "                                             chain_strength=chain_strength)\n",
    "    \n",
    "    partition = [sum(samplesets[qpu].first.sample.values()), graph_nodes - sum(samplesets[qpu].first.sample.values())]\n",
    "    avg_breaks = 100*sum(samplesets[qpu].record.chain_break_fraction)/num_reads\n",
    "    print(\"Partition for {} is {} with lowest energy {:.3f}.\".format(qpu, partition, samplesets[qpu].first.energy))\n",
    "    print(\"Chain breaks for {} is {:.3f} percent.\".format(qpu, avg_breaks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dimod\n",
    "(h, J, offset) = dimod.qubo_to_ising(Q)\n",
    "\n",
    "range_h = [min(h[key] for key in h.keys()), \n",
    "               max(h[key] for key in h.keys())]\n",
    "range_J = [min(J[key] for key in J.keys()), \n",
    "               max(J[key] for key in J.keys())]\n",
    "\n",
    "print(\"Range h {}\".format(range_h))\n",
    "print(\"Range J {}\".format(range_J))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUBO --> ISING\n",
    "samplers = {\"sampler_\" + str(qpu): EmbeddingComposite(qpus[qpu]) for qpu in qpus}\n",
    "\n",
    "samplesets = {}\n",
    "for qpu, sampler in samplers.items():  \n",
    "    samplesets[qpu] = sampler.sample_ising(h, J, \n",
    "                                           num_reads=num_reads, \n",
    "                                           auto_scale=True,\n",
    "                                           chain_strength=4000)\n",
    "    \n",
    "    partition_miss = sum(samplesets[qpu].first.sample.values())\n",
    "    avg_breaks = 100*sum(samplesets[qpu].record.chain_break_fraction)/num_reads\n",
    "    print(\"Partition miss for {} is {} with lowest energy {:.3f}.\".format(qpu, partition_miss, samplesets[qpu].first.energy))\n",
    "    print(\"Chain breaks for {} is {:.3f} percent.\".format(qpu, avg_breaks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_ising(h, J, factor=1.0):\n",
    "    range_h = [min(h[key] for key in h.keys()), \n",
    "               max(h[key] for key in h.keys())]\n",
    "    range_J = [min(J[key] for key in J.keys()), \n",
    "               max(J[key] for key in J.keys())]\n",
    "    \n",
    "    scaling_h = max(range_h[0]/-1.0, range_h[1]/1.0)\n",
    "    scaling_J = max(range_J[0]/-1.0, range_J[1]/1.0)\n",
    "    scaling = max(scaling_h, scaling_J)\n",
    "    return dict((key, factor*h[key]/scaling) for key in h.keys()), dict((key, factor*J[key]/scaling) for key in J.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_scaled, J_scaled =  scaled_ising(h, J, factor=0.1)\n",
    "\n",
    "range_hs = [min(h_scaled[key] for key in h_scaled.keys()), \n",
    "               max(h_scaled[key] for key in h_scaled.keys())]\n",
    "range_Js = [min(J_scaled[key] for key in J_scaled.keys()), \n",
    "               max(J_scaled[key] for key in J_scaled.keys())]\n",
    "\n",
    "print(\"Range h {}\".format(range_hs))\n",
    "print(\"Range J {}\".format(range_Js))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dwave.embedding import embed_ising\n",
    "\n",
    "chain_strength_scaled = 2.\n",
    "\n",
    "embedded_vals = {}\n",
    "for qpu in qpus: \n",
    "    embedded_vals[qpu] = embed_ising(h_scaled, \n",
    "                                          J_scaled, \n",
    "                                          best_embedding[qpu][0], \n",
    "                                          qpus[qpu].adjacency, \n",
    "                                          chain_strength=chain_strength_scaled)\n",
    "    \n",
    "    print(\"{} J: {}\".format(qpu, sorted(set(embedded_vals[qpu][1][key] \n",
    "                            for key in embedded_vals[qpu][1].keys()))))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 8))\n",
    "axis = 1\n",
    "for qpu_name, qpu in qpus.items(): \n",
    "    ax = \"ax\"+str(axis)\n",
    "    ax = plt.subplot(2, 1, axis)\n",
    "    ax.set_title(\"Sampler: \" + qpu_name)\n",
    "    ax.set_xlabel(\"--\")\n",
    "    ax.set_ylabel(\"J\")\n",
    "    ax.plot(range(len(embedded_vals[qpu_name][1])), embedded_vals[qpu_name][1].values(), 'bo')\n",
    "    axis += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dwave.embedding import unembed_sampleset, chain_break_frequency\n",
    "\n",
    "num_reads = 5000\n",
    "\n",
    "samplesets_embedded = {}\n",
    "samplesets = {}\n",
    "chain_breaks = {}\n",
    "\n",
    "for qpu in qpus:  \n",
    "    samplesets_embedded[qpu] = qpus[qpu].sample_ising(embedded_vals[qpu][0], \n",
    "                                           embedded_vals[qpu][1], \n",
    "                                           num_reads=num_reads,\n",
    "                                           answer_mode='histogram',\n",
    "                                           auto_scale=False)\n",
    "    samplesets[qpu] = unembed_sampleset(target_sampleset=samplesets_embedded[qpu], \n",
    "                                        embedding=best_embedding[qpu][0], \n",
    "                                        source_bqm=dimod.BinaryQuadraticModel.from_ising(h, J), \n",
    "                                        chain_break_method=None, \n",
    "                                        chain_break_fraction=True, \n",
    "                                        return_embedding=True)\n",
    "    \n",
    "    partition_miss = sum(samplesets[qpu].first.sample.values())\n",
    "    print(\"Partition miss for {} is {} with lowest energy {:.3f}.\".format(qpu, partition_miss, samplesets[qpu].first.energy))\n",
    "\n",
    "    chain_breaks[qpu] = chain_break_frequency(samplesets_embedded[qpu], \n",
    "                                                          best_embedding[qpu][0])\n",
    "    print(qpu, \":\", {key:100*val for key, val in chain_breaks[qpu].items()})            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplesets[\"advantage\"].record.chain_break_fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, absolute_import\n",
    "\n",
    "import dimod\n",
    "import numpy as np\n",
    "\n",
    "from six import iteritems\n",
    "\n",
    "from dwave.embedding.chain_breaks import broken_chains\n",
    "\n",
    "\n",
    "def my_chain_break_frequency(samples_like, embedding):\n",
    "    \"\"\"Determine the frequency of chain breaks in the given samples.\n",
    "\n",
    "    Args:\n",
    "        samples_like (samples_like/:obj:`dimod.SampleSet`):\n",
    "            A collection of raw samples. 'samples_like' is an extension of NumPy's array_like.\n",
    "            See :func:`dimod.as_samples`.\n",
    "\n",
    "        embedding (dict):\n",
    "            Mapping from source graph to target graph as a dict of form {s: {t, ...}, ...},\n",
    "            where s is a source-model variable and t is a target-model variable.\n",
    "\n",
    "    Returns:\n",
    "        dict: Frequency of chain breaks as a dict in the form {s: f, ...},  where s\n",
    "        is a variable in the source graph and float f the fraction\n",
    "        of broken chains.\n",
    "\n",
    "    Examples:\n",
    "        This example embeds a single source node, 'a', as a chain of two target nodes (0, 1)\n",
    "        and uses :func:`.chain_break_frequency` to show that out of two synthetic samples,\n",
    "        one ([-1, +1]) represents a broken chain.\n",
    "\n",
    "        >>> import numpy as np\n",
    "        ...\n",
    "        >>> samples = np.array([[-1, +1], [+1, +1]])\n",
    "        >>> embedding = {'a': {0, 1}}\n",
    "        >>> print(dwave.embedding.chain_break_frequency(samples, embedding)['a'])\n",
    "        0.5\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    if isinstance(samples_like, dimod.SampleSet):\n",
    "        labels = samples_like.variables\n",
    "        samples = samples_like.record.sample\n",
    "        num_occurrences = samples_like.record.num_occurrences\n",
    "    else:\n",
    "        samples, labels = dimod.as_samples(samples_like)\n",
    "        num_occurrences = np.ones(samples.shape[0])\n",
    "\n",
    "    if not all(v == idx for idx, v in enumerate(labels)):\n",
    "        labels_to_idx = {v: idx for idx, v in enumerate(labels)}\n",
    "        embedding = {v: {labels_to_idx[u] for u in chain} for v, chain in embedding.items()}\n",
    "\n",
    "    if not embedding:\n",
    "        return {}\n",
    "\n",
    "    variables, chains = zip(*embedding.items())\n",
    "\n",
    "    broken = broken_chains(samples, chains)\n",
    "\n",
    "    return {v: float(np.average(broken[:, cidx], weights=num_occurrences))\n",
    "            for cidx, v in enumerate(variables)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright &copy; D-Wave Systems Inc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": "1",
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "229px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the Topology of Pegasus\n",
    "D-Wave's newest quantum computer, Advantage, introduces a quantum processing unit (QPU) with a new architecture: the Pegasus family of topologies. This notebook explains the Pegasus topology and demonstrates its enhanced performance over QPUs of the previous generation used in the DW-2000Q system. \n",
    "    \n",
    "1. [The Pegasus Advantage](#The-Pegasus-Advantage) shows the differences between the previous and new topologies and their usefulness.\n",
    "2. [Navigating the Topology](#Navigating-the-Topology) demonstrates Ocean tools that help you use this QPU.\n",
    "3. [Example Problem: RAN-K](#Example-Problem:-RAN-K) solves a hard problem on two generations of systems.\n",
    "\n",
    "This notebook should familiarize you with the new Pegasus topology and the tools to use it.\n",
    "\n",
    "<img src=\"images/anim.gif\" width=200x/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**New to Jupyter Notebooks?** JNs are divided into text or code cells. Pressing the **Run** button in the menu bar moves to the next cell. Code cells are marked by an \"In: \\[\\]\" to the left; when run, an asterisk displays until code completion: \"In: \\[\\*\\]\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Pegasus Advantage\n",
    "\n",
    "The Advantage system is distinct from all previous generations of D-Wave quantum computers in the technological advance made by its new QPU architecture. \n",
    "\n",
    "The D-Wave QPU is a lattice of interconnected qubits. While some qubits connect to others via couplers, D-Wave QPUs are not fully connected. Instead, the qubits interconnect in an topology: Chimera for the 2000Q and Pegasus for the Advantage.\n",
    "\n",
    "This layout of the D-Wave QPU is critical to translating a QUBO or Ising objective function into a format that a D-Wave system can solve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minor-Embedding: Mapping a Problem to Qubits\n",
    "\n",
    "<div class=\"alert alert-warning\" role=\"alert\" style=\"margin: 10px\">Note: If you already understand how problems are mapped to the D-Wave system, please skip ahead to the next text cell.</div>\n",
    " \n",
    "D-Wave systems solve binary quadratic models (BQM), the Ising model traditionally used in statistical mechanics and its computer-science equivalent, the quadratic unconstrained binary optimization (QUBO) problem. Given $N$ variables $x_1,...,x_N$, where each variable $x_i$ can have binary values $0$ or $1$, the system finds assignments of values that minimize\n",
    "\n",
    "$\\sum_i^N q_ix_i + \\sum_{i<j}^N q_{i,j}x_i  x_j$,\n",
    "\n",
    "where $q_i$ and $q_{i,j}$ are configurable (linear and quadratic) coefficients. \n",
    "\n",
    "Such objective functions can be represented by graphs. A graph comprises a collection of nodes (representing variables) and the connections between them (edges). For example, a Boolean AND, $z \\Leftrightarrow x_1 \\wedge x_2$, expressed in QUBO formulation as, \n",
    "\n",
    "$x_1 x_2 - 2(x_1+x_2)z +3z$, \n",
    "\n",
    "is represented by the graph:\n",
    "\n",
    "<img src=\"images/embedding_and.png\" width=300x/>\n",
    "\n",
    "To formulate a problem for the D-Wave system is to program $q_i$ and $q_{i,j}$ so that assignments of $x_1,...,x_N$ also represent solutions to the problem. This requires that the problem graph be mapped to the QPU. [Minor embedding](#https://docs.ocean.dwavesys.com/en/stable/concepts/embedding.html#embedding-sdk) maps problem variables ($x_1, x_2, z$ for the AND gate) to the indexed qubits of the D-Wave QPU. On the D-Wave system, nodes are qubits and edges are couplers.\n",
    "\n",
    "Were qubits on a QPU fully connected, with every qubit coupled to every other qubit, you could simply map each problem variable (graph node) to a qubit and each quadratic interaction (graph edge) to a coupler. But with sparser QPU topologies, a variable might be represented by a *chain* of two or more qubits. \n",
    "\n",
    "For example, the AND is represented by a $K_3$ fully connected graph (left graph in the figure below), and that cannot be mapped directly to a Chimera topology. Instead, a chain using two of four not-fully-connected qubits (the  middle graph below) is used to represent a single variable (right graph), here qubit 0 and qubit 4 to represent variable $z$.\n",
    "\n",
    "<img src=\"images/embedding_chimera_and.png\" width=500x/>\n",
    "\n",
    "The strength of the coupler between qubits 0 and 4, which represents\n",
    "variable $z$, is set to correlate the qubits strongly, so that in most\n",
    "solutions they have a single value for $z$. \n",
    "\n",
    "Ocean software provides tools that handle minor-embedding. One such minor-embedding on a D-Wave 2000Q is displayed below using the Ocean software's [dwave-inspector](#https://docs.ocean.dwavesys.com/en/stable/docs_inspector/sdk_index.html) tool. The problem graph, shown on the left, is embedded in four qubits , shown on the right against a background of the Chimera topology. The variable highlighted in dark magenta is represented by two qubits, numbers 251 and 253 in this particular embedding.\n",
    "\n",
    "<img src=\"images/embedding_3var4qubits.png\" width=500x/>\n",
    "\n",
    "The size and complexity of problems that can be submitted to a quantum computer depends on the QPU's *working graph*, the set of qubits and couplers that are available for computation. Adding qubits expands the QPU's range, obviously, but  denser connectivity reduces the wasting of qubits in representing single variables with chains of multiple qubits, which can also affect solution quality. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Pegasus topology enables the Advantage QPU to more than double the number of available qubits compared to the 2000Q, and the working graph is denser, meaning each qubit is coupled to a greater number of neighboring qubits. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Qubits\n",
    "This subsection looks at the straightforward increase in qubit numbers between the new and previous generation QPUs. \n",
    "\n",
    "It also introduces useful Ocean software tools that let you work with the QPU topology locally on your computer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dwave_networkx as dnx\n",
    "\n",
    "C = dnx.chimera_graph(16)\n",
    "P = dnx.pegasus_graph(16)\n",
    "\n",
    "print(\"Qubits in full working graph: \\n    Chimera: {} \\n    Advantage: {}\".format(len(C.nodes), len(P.nodes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(14,6))\n",
    "dnx.draw_chimera(C, ax=ax[0], node_size=5, node_color='g')\n",
    "dnx.draw_pegasus(P, ax=ax[1], node_size=5, node_color='b')\n",
    "ax[0].title.set_text('Chimera C16')\n",
    "ax[1].title.set_text('Pegasus P16')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intuitively, you can scale up the size of problems embedded on a QPU more if they are sparse because these come closer to representing a string of variables connected head to tail by a similar string of qubits.\n",
    "\n",
    "The next cells define a couple of functions used throughout this section:\n",
    "\n",
    "* `generate_ran1` generates a problem with `variables` number of variables and `interactions` density of interactions.\n",
    "* `try_embedding` tries to embed a problem in both the Chimera and Pegasus graphs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import dimod \n",
    "\n",
    "def generate_ran1(variables, interactions, draw=True):\n",
    "    \n",
    "    G = nx.random_regular_graph(n=variables, d=interactions)\n",
    "    bqm = dimod.generators.random.ran_r(1, G)\n",
    "    \n",
    "    if draw:\n",
    "        plt.figure(figsize=(7, 7))\n",
    "        nx.draw_networkx(G, pos=nx.spring_layout(G), with_labels=False, node_size=25) \n",
    "        plt.show()\n",
    "            \n",
    "    return bqm\n",
    "\n",
    "bqm = generate_ran1(100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import minorminer\n",
    "\n",
    "def try_embedding(bqm, timeout=60, tries=2):\n",
    "    \n",
    "    max_len = {}\n",
    "    for topology in [('Chimera', C), ('Pegasus', P)]:\n",
    "        \n",
    "        embedding = minorminer.find_embedding(bqm.quadratic, \n",
    "                                          topology[1].edges, \n",
    "                                          timeout=timeout, \n",
    "                                          tries=tries)\n",
    "        if not embedding:\n",
    "            print(\"{}: failed to embed.\".format(topology[0]))\n",
    "        else:\n",
    "            max_len[topology[0]] = max([len(embedding[n]) for n in embedding])\n",
    "            print(\"{}: found embedding with longest chain of {} qubits.\".format(topology[0], max_len[topology[0]]))\n",
    "            \n",
    "    return max_len\n",
    "\n",
    "answer = try_embedding(bqm, timeout=20, tries=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try embedding problems with sizes that range from a quarter of the qubits in a full Chimera graph to nearly all the qubits. \n",
    "\n",
    "<div class=\"alert alert-warning\" role=\"alert\" style=\"margin: 10px\">Note: In this and similar code cells below, you can shorten the runtime by setting a lower value to the `problems` parameter, representing the number of problems of each size, and/or the list different sizes, `variables`, set for the loop.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions = 2\n",
    "problems = 2\n",
    "\n",
    "draw_problem = True  # Change to false to not display problem graphs \n",
    "\n",
    "for variables in [500, 1000, 2000]:\n",
    "        \n",
    "    for problem in range(problems):\n",
    "        \n",
    "        print(\"\\nProblem {} of {} for {} variables:\".format(problem + 1, \n",
    "                                                            problems, \n",
    "                                                            variables))\n",
    "        \n",
    "        bqm = generate_ran1(variables, interactions, draw_problem)\n",
    "        try_embedding(bqm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, you see that even for sparse problems, connectivity plays a crucial role in enabling you to embed large problems in a QPU. The power of the Pegasus topology comes from its higher connectivity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Increased Connectivity\n",
    "\n",
    "To properly appreciate the contribution of increasing the density of the QPU topology, increase the sparse problem's connectivity from 2 to 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "interactions = 3\n",
    "problems = 2\n",
    "\n",
    "draw_problem = True  # Change to false to not display problem graphs \n",
    "\n",
    "row = []\n",
    "df_columns = [\"Variables\", \"Problem\", \"Longest Chain\"]\n",
    "\n",
    "for variables in [100, 200, 400, 800]:\n",
    "        \n",
    "    for problem in range(problems):\n",
    "        \n",
    "        print(\"\\nProblem {} of {} for {} variables:\".format(problem + 1, \n",
    "                                                            problems, \n",
    "                                                            variables))\n",
    "        \n",
    "        bqm = generate_ran1(variables, interactions, draw_problem)\n",
    "        \n",
    "        row.append([variables, problem, try_embedding(bqm)])\n",
    "\n",
    "results = pd.DataFrame(row, columns=df_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the fast growth of chain lengths even for such sparse problems. \n",
    "\n",
    "Try raising density for a relatively small, 100-variables problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = 100\n",
    "problems = 2\n",
    "\n",
    "draw_problem = True  # Change to false to not display problem graphs \n",
    "\n",
    "row = []\n",
    "df_columns = [\"Interaction\", \"Problem\", \"Longest Chain\"]\n",
    "\n",
    "for interactions in range(2, 16, 2):\n",
    "        \n",
    "    for problem in range(problems):\n",
    "        \n",
    "        print(\"\\nProblem {} of {} for {} interactions:\".format(problem + 1, \n",
    "                                                            problems, \n",
    "                                                            interactions))\n",
    "        \n",
    "        bqm = generate_ran1(variables, interactions, draw_problem)\n",
    "        \n",
    "        row.append([interactions, problem, try_embedding(bqm)])\n",
    "\n",
    "results = pd.DataFrame(row, columns=df_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(results[\"Interaction\"], results[\"Longest Chain\"].apply(lambda x: x['Chimera']), 0.35, label='Chimera')\n",
    "rects2 = ax.bar(results[\"Interaction\"], results[\"Longest Chain\"].apply(lambda x: x['Pegasus']), 0.35, label='Pegasus')\n",
    "\n",
    "ax.set_ylabel('Longest Chain')\n",
    "ax.set_xlabel('Interactions')\n",
    "ax.set_title('Longest Chains for Each Topology')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preceding cells should have demonstrated two important points: \n",
    "\n",
    "* A topology with denser connectivity enables you to scale up your problems in terms of both the number of variables and the density of the variables' interactions.\n",
    "* Minor-embedding heuristic algorithms can be slow. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clique Embeddings\n",
    "Clique embeddings can be very useful. A minor-embedding for a $K_n$ fully connected graph can be used for all minors of that graph. This means that if your application needs to submit a series of problems of up to size $n$ to the QPU, if you have an embedding for the $K_n$ graph on the QPU, you can simply reuse that embedding for all your problems.  \n",
    "\n",
    "As an intuitive example, the $K_3$ minor-embedding explained above can be reused to embed a two-variable problem, $x_1x_2$ by not setting the values of variable $z$ and its couplers:\n",
    "\n",
    "<img src=\"images/embedding_clique_k3_2vars.png\" width=500x/>\n",
    "\n",
    "\n",
    "<div class=\"alert alert-warning\" role=\"alert\" style=\"margin: 10px\">Note that if your problems are sparse, using a clique embedding can be very wasteful, needlessly restricting the number of variables you can scale up to.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding in a Single Chimera Unit-Cell ($K_{4,4}$)\n",
    "Many problems have repetitive structures or can be formulated with repeated, small elements; for example, a problem expressed using Boolean elements such as the AND expression above. In such cases, it's advantageous to minor-embed the problem in a way that exploits the lattice structure of the QPU.  \n",
    "\n",
    "The Chimera topology's simpler structure is based on a 16x16 grid of *unit cells*, each with four horizontal qubits connected to four vertical qubits via couplers. \n",
    "\n",
    "The figure below shows a 3x3 lattice of Chimera unit cells.\n",
    "<img src=\"images/chimera.png\" width=300x/>\n",
    "If repeated structures of a problem can be embedded in a unit cell, you might then be able to repeat those structures across other unit cells in the lattice. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try minor-embedding cliques of varying sizes into a Chimera unit cell and an equivalent $K_{4,4}$ structure of the Pegasus topology, which is explained in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C1 = dnx.chimera_graph(1)\n",
    "P1 = dnx.pegasus_graph(2, node_list=[4, 5, 6, 7, 40, 41, 42, 43])\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(14,6))\n",
    "dnx.draw_chimera(C1, ax=ax[0], node_size=2000, with_labels=True, node_color='g')\n",
    "dnx.draw_pegasus(P1, ax=ax[1], node_size=2000, with_labels=True, node_color='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from dwave.embedding import *\n",
    "\n",
    "for variables in range(2, 7):\n",
    "    \n",
    "    try:\n",
    "        embedding = chimera.find_clique_embedding(variables, 1, target_edges=C1.edges)\n",
    "        print(\"Chimera: embedded {} variables with longest chain of {}.\".format(variables, max([len(chain) for chain in embedding.values()])))\n",
    "    except ValueError:\n",
    "        print(\"Chimera: embedding {} variables failed.\".format(variables))\n",
    "\n",
    "    try:\n",
    "        #embedding = pegasus.find_clique_embedding(variables, target_graph=P1)\n",
    "        embedding = minorminer.find_embedding(nx.complete_graph(variables), P1.edges)\n",
    "        print(\"Pegasus: embedded {} variables with longest chain of {}.\\n\".format(variables, max([len(chain) for chain in embedding.values()])))\n",
    "    except ValueError:\n",
    "        print(\"Pegasus: embedding {} variables failed.\\n\".format(variables))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are [dwave-inspector](#https://docs.ocean.dwavesys.com/en/stable/docs_inspector/sdk_index.html) images of a $K_{5,5}$ clique embedded in the Chimera topology and a $K_{6,6}$ clique embedded in the Pegasus topology:\n",
    "\n",
    "<img src=\"images/k_55_chimera.png\" width=400x/>\n",
    "\n",
    "<img src=\"images/k_66_pegasus.png\" width=400x/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Largest Cliques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a given maximum chain length, you can embed a clique of the following sizes in Pegasus and Chimera graphs: \n",
    "\n",
    "| Chain Length | 2 | 3  | 4  | 5  | 6  | 7  | 8  | 9  | 10 | 11 | 12 | 13 | 14 |\n",
    "|--------------|---|----|----|----|----|----|----|----|----|----|----|----|----|\n",
    "| Chimera      | 4 | 8  | 12 | 16 | 20 | 24 | 28 | 32 | 36 | 40 | 44 | 48 | 52 |\n",
    "| Pegasus      | 6 | 16 | 26 | 36 | 42 | 49 |    |    |    |    |    |    |    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DRAFT CONTENT\n",
    "\n",
    "In general, you can let Ocean automatically handle minor-embedding for you. But performance for some problems can be enhanced by intelligent manual adjustments. The next section explains the topology.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navigating the Topology\n",
    "You've seen the importance of connectivity. The connectivity of a QPU comes from its couplers. A 2000Q QPU has X couplers; an Advantage QPU has Y couplers. \n",
    "\n",
    "You have also seen the lattice structure of the QPU and an example of its importance for embedding your problem.\n",
    "\n",
    "These two are aspects of the same thing: the lattice structure is determined by the couplings of its qubits.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chimera qubits are “oriented” on the QPU vertically or horizontally and coupled by one of two categories of couplers:\n",
    "\n",
    "* *Internal couplers* connect pairs of orthogonal (with opposite orientation) qubits. Each qubit is connected via internal coupling to 4 other qubits.\n",
    "\n",
    "* *External couplers* connect colinear pairs of qubits---pairs of parallel qubits in the same row or column.\n",
    "\n",
    "In the figure below, green circles at the intersections of qubits signify internal couplers; external couplers, shown as connected blue circles, couple vertical qubits to adjacent vertical qubits and horizontal qubits to adjacent horizontal qubits. The green horizontal qubit in the center couples internally to four vertical qubits, bolded black, in its own unit cell and to the two blue horizontal qubits in adjacent unit cells. \n",
    "\n",
    "<img src=\"images/chimera_couplers.png\" width=400x/>\n",
    "\n",
    "Chimera qubits are characterized as having:\n",
    "\n",
    "* Nominal length 4&mdash;each qubit is connected to 4 orthogonal qubits through internal couplers.\n",
    "* Degree 6&mdash;each qubit is coupled to 6 different qubits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot four Chimera unit cells and notice the couplings: internal couplers connecting vertical and horizontal qubits of each cell (short edges) and external couplers connecting similarly oriented qubits of different unit cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import dwave_networkx as dnx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "C = dnx.chimera_graph(2)\n",
    "    \n",
    "dnx.draw_chimera(C, with_labels=True, node_size=500, node_color='g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When exploiting the underlying structure of the topology it can be helpful to use a coordinate system based on the structure. Qubits in the depictions above of unit cells are shown with the indexical label scheme, but for navigating, you might prefer coordinates based on the qubit position within a unit cell and the cell's place in the latticed.\n",
    "\n",
    "For an m-by-n Chimera lattice, connections can be expressed using a node-indexing notation (i,j,u,k) for each node.\n",
    "\n",
    "* (i,j) indexes the (row, column) of the Chimera tile. i must be between 0 and m-1, inclusive, and j must be between 0 and n-1, inclusive.\n",
    "* u=0 indicates the left-hand nodes in the tile, and u=1 indicates the right-hand nodes.\n",
    "* k=0,1,…,t-1 indexes nodes within either the left- or right-hand shores of a tile.\n",
    "\n",
    "For the C2 Chimera lattice above show the *Chimera coordinate* of the second vertical and horizontal qubit in each cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 32, 4):\n",
    "    print(\"qubit {} has Chimera coordinates {}\".format(i, C.nodes(data=True)[i]['chimera_index']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ocean utilities are available to translate between coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = dnx.chimera_coordinates(2)\n",
    "\n",
    "i = 13\n",
    "c = (1, 1, 0, 1)\n",
    "\n",
    "print(\"Qubit {} has Chimera coordinates {}.\".format(i, coords.linear_to_chimera(i)))\n",
    "print(\"Chimera coordinates {} designate qubit {}.\".format(c, coords.chimera_to_linear(c)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pegasus qubits are also oriented on the QPU vertically or horizontally but they are coupled by one of three categories of couplers:\n",
    "\n",
    "* Internal couplers connect pairs of orthogonal (with opposite orientation) qubits. Each qubit is connected via internal coupling to 12 other qubits.\n",
    "\n",
    "  In comparison with Chimera, internal coupling in Pegasus connects each qubit\n",
    "  to qubits of opposite orientation in repeated substructures that include more\n",
    "  than a the internal couplings of a single Chimera unit cell (a $K_{4,4}$\n",
    "  bipartite graph.\n",
    "\n",
    "* External couplers connect vertical qubits to adjacent vertical qubits and horizontal qubits to adjacent horizontal qubits.\n",
    "\n",
    "* *Odd couplers* connect similarly aligned pairs of qubit sin the same Chimera unit cell, a vertical qubit to another vertical qubit and a horizontal qubit to another horizontal qubit.\n",
    "\n",
    "The figure below provides a helpful way to envision a recurring structure of the Pegasus topology, similar to the unit cells of Chimera: the division of\n",
    "internal couplings into $K_{4,4}$ bipartite graphs abstracted as three layers of\n",
    "Chimera lattices. In this abstraction, each qubit forms part, through its\n",
    "internal couplers, of a Chimera unit cell in one layer (translucent green square) while\n",
    "additionally coupling to four qubits of a unit cell in a second layer (translucent blue square)\n",
    "and two qubits each of two units cells in a third layer (translucent pink squares).\n",
    "\n",
    "<img src=\"images/pegasus_zlayered_unitcells.png\" width=400x/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = dnx.pegasus_graph(2)\n",
    "\n",
    "for i in range(2, 14):\n",
    "    print(\"Qubit {} has Pegasus coordinates {}.\".format(i, P.nodes(data=True)[i]['pegasus_index']))\n",
    "\n",
    "H = dnx.pegasus_graph(2, node_list=[node for node in range(2, 14)])\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8,8))\n",
    "dnx.draw_pegasus(P, ax=ax, with_labels=True, node_size=500, node_color='b')\n",
    "dnx.draw_pegasus(H, ax=ax, node_color='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Problem: RAN-K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solver Availability\n",
    "This subsection checks whether you have access to both generations of solvers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dwave.system.samplers import DWaveSampler\n",
    "from dwave.cloud.exceptions import *\n",
    "\n",
    "try:\n",
    "    qpu_advantage = DWaveSampler(solver={'topology__type': 'pegasus', 'qpu': True})\n",
    "    qpu_2000q = DWaveSampler(solver={'topology__type': 'chimera', 'qpu': True})\n",
    "    \n",
    "    qpus = {'advantage': qpu_advantage, '2000q': qpu_2000q}\n",
    "\n",
    "    print(\"Connected to Advantage {} and 2000Q {}.\".format(qpu_advantage.solver.id, qpu_2000q.solver.id))\n",
    "except SolverNotFoundError:\n",
    "    print(\"Currently a pair of solvers are unavailable for sections comparing QPU technologies. Try those examples later.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Problem: Graph Partitioning \n",
    "There a "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formulating the Problem\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "import random\n",
    "import networkx as nx\n",
    "\n",
    "num_clusters = 20\n",
    "clusters = [random.randint(2, 3) for x in range(num_clusters)]\n",
    "G = nx.random_partition_graph(sizes=clusters, p_in=0.2, p_out=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "graph_nodes = 10\n",
    "cluster_size = 3\n",
    "density = 0.5\n",
    "density_external = 0.05\n",
    "G = nx.planted_partition_graph(l=graph_nodes, k=cluster_size, p_in=density, p_out=density_external)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.LFR_benchmark_graph(n=40, \n",
    "                           tau1=5, \n",
    "                           tau2=4, \n",
    "                           mu=0.2, \n",
    "                           average_degree=3,  \n",
    "                           max_degree=5, \n",
    "                           min_community=10, \n",
    "                           max_community=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(7, 7))\n",
    "nx.draw_networkx(G, pos=nx.spring_layout(G)) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "import networkx as nx\n",
    "\n",
    "graph_nodes = 10\n",
    "G = nx.complete_graph(graph_nodes)\n",
    "\n",
    "density = 1\n",
    "gamma = 0.5*(0.5*graph_nodes*(graph_nodes - 1))*density\n",
    "chain_strength = gamma*graph_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "graph_nodes = 40\n",
    "density = 1\n",
    "G = nx.erdos_renyi_graph(n=graph_nodes, p=density)\n",
    "\n",
    "gamma = 0.5*(0.5*graph_nodes*(graph_nodes - 1))*density\n",
    "chain_strength = gamma*graph_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(7, 7))\n",
    "nx.draw_networkx(G, pos=nx.spring_layout(G)) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Ising Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "nodes = ['a', 'b', 'c']\n",
    "edges = [('a', 'b'), ('b', 'c')]\n",
    "\n",
    "h = {'a': 2, 'b': 0, 'c': -2}\n",
    "J = {edge: 1.5 for edge in edges}\n",
    "\n",
    "print(h, J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_embedding = {'advantage': {'a': [336], \n",
    "                                'b': [479, 321], \n",
    "                                'c': [524]},\n",
    "                 '2000q': {'a': [1445], 'b': [1447, 1443], 'c': [1441]}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dwave.system import FixedEmbeddingComposite\n",
    "samplers = {qpu: FixedEmbeddingComposite(qpus[qpu], best_embedding[qpu]) for qpu in qpus}\n",
    "\n",
    "samplesets = {}\n",
    "for qpu in qpus:  \n",
    "    samplesets[qpu] = samplers[qpu].sample_ising(h, J,\n",
    "                                           num_reads=num_reads, \n",
    "                                           auto_scale=True,\n",
    "                                           chain_strength=1.5)\n",
    "    \n",
    "    avg_breaks = 100*sum(samplesets[qpu].record.chain_break_fraction)/num_reads\n",
    "    print(\"Chain breaks for {} is {:.3f} percent.\".format(qpu, avg_breaks))\n",
    "    print(samplesets[qpu])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_ising(h, J, factor=1.0):\n",
    "    range_h = [min(h[key] for key in h.keys()), \n",
    "               max(h[key] for key in h.keys())]\n",
    "    range_J = [min(J[key] for key in J.keys()), \n",
    "               max(J[key] for key in J.keys())]\n",
    "    \n",
    "    scaling_h = max(range_h[0]/-1.0, range_h[1]/1.0)\n",
    "    scaling_J = max(range_J[0]/-1.0, range_J[1]/1.0)\n",
    "    scaling = max(scaling_h, scaling_J)\n",
    "    return dict((key, factor*h[key]/scaling) for key in h.keys()), dict((key, factor*J[key]/scaling) for key in J.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_scaled, J_scaled =  scaled_ising(h, J, factor=1.0)\n",
    "\n",
    "range_hs = [min(h_scaled[key] for key in h_scaled.keys()), \n",
    "               max(h_scaled[key] for key in h_scaled.keys())]\n",
    "range_Js = [min(J_scaled[key] for key in J_scaled.keys()), \n",
    "               max(J_scaled[key] for key in J_scaled.keys())]\n",
    "\n",
    "print(\"Range h {}\".format(range_hs))\n",
    "print(\"Range J {}\".format(range_Js))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dwave.embedding import embed_ising\n",
    "\n",
    "chain_strength_scaled = 0.75\n",
    "\n",
    "embedded_vals = {}\n",
    "for qpu in qpus: \n",
    "    embedded_vals[qpu] = embed_ising(h_scaled, \n",
    "                                          J_scaled, \n",
    "                                          best_embedding[qpu], \n",
    "                                          qpus[qpu].adjacency, \n",
    "                                          chain_strength=chain_strength_scaled)\n",
    "    \n",
    "    print(\"{} J: {}\".format(qpu, sorted(set(embedded_vals[qpu][1][key] \n",
    "                            for key in embedded_vals[qpu][1].keys()))))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 8))\n",
    "axis = 1\n",
    "for qpu_name, qpu in qpus.items(): \n",
    "    ax = \"ax\"+str(axis)\n",
    "    ax = plt.subplot(2, 1, axis)\n",
    "    ax.set_title(\"Sampler: \" + qpu_name)\n",
    "    ax.set_xlabel(\"--\")\n",
    "    ax.set_ylabel(\"J\")\n",
    "    ax.plot(range(len(embedded_vals[qpu_name][1])), embedded_vals[qpu_name][1].values(), 'bo')\n",
    "    axis += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplesets_embedded = {}\n",
    "for qpu in qpus:  \n",
    "    samplesets_embedded[qpu] = qpus[qpu].sample_ising(embedded_vals[qpu][0], \n",
    "                                           embedded_vals[qpu][1], \n",
    "                                           num_reads=num_reads,\n",
    "                                           answer_mode='histogram',\n",
    "                                           auto_scale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dwave.embedding import unembed_sampleset, chain_break_frequency\n",
    "\n",
    "samplesets = {}\n",
    "for qpu in qpus:  \n",
    "        \n",
    "    samplesets[qpu] = unembed_sampleset(target_sampleset=samplesets_embedded[qpu], \n",
    "                                        embedding=best_embedding[qpu], \n",
    "                                        source_bqm=dimod.BinaryQuadraticModel.from_ising(h, J), \n",
    "                                        chain_break_method=None, \n",
    "                                        chain_break_fraction=True, \n",
    "                                        return_embedding=True)\n",
    "    \n",
    "    avg_breaks = 100*sum(samplesets[qpu].record.chain_break_fraction)/num_reads\n",
    "    print(\"Chain breaks for {} is {:.3f} percent.\".format(qpu, avg_breaks))\n",
    "    print(samplesets[qpu])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph --> QUBO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "\n",
    "\n",
    "Q = defaultdict(int)\n",
    "\n",
    "# Fill in Q matrix\n",
    "for u, v in G.edges:\n",
    "    Q[(u,u)] += 1\n",
    "    Q[(v,v)] += 1\n",
    "    Q[(u,v)] += -2\n",
    "\n",
    "for i in G.nodes:\n",
    "    Q[(i,i)] += gamma*(1-len(G.nodes))\n",
    "\n",
    "for i, j in combinations(G.nodes, 2):\n",
    "    Q[(i,j)] += 2*gamma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitting for Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minor Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import minorminer\n",
    "import numpy as np\n",
    "\n",
    "embedding_tries = 1\n",
    "\n",
    "best_embedding = defaultdict(lambda: ({}, 1000))\n",
    "for qpu in qpus:\n",
    "    print(\"\\nFinding a good embedding for {}:\\n\".format(qpu))\n",
    "    for i in range(embedding_tries):\n",
    "        embedding = minorminer.find_embedding(Q.keys(), qpus[qpu].edgelist, timeout=60, tries=1)\n",
    "        if not embedding:\n",
    "            print(\"   Failed to find an embedding {}.\".format(i))\n",
    "        else:\n",
    "            chain_lengths = list(len(chain) for chain in embedding.values())\n",
    "            avg_chain = np.average(chain_lengths)\n",
    "            print(\"    Embedding {} chain lengths: {:.2f} average, {:.2f} std, {} max, {} min.\".\n",
    "                  format(i,\n",
    "                         avg_chain,\n",
    "                         np.std(chain_lengths),\n",
    "                         np.max(chain_lengths),\n",
    "                         np.min(chain_lengths)))\n",
    "            if avg_chain < best_embedding[qpu][1]:\n",
    "                best_embedding[qpu] = (embedding, avg_chain) \n",
    "    print(\"Best for {} has average length {}.\\n\".format(qpu, best_embedding[qpu][1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Virtual Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_qubo(Q, factor=1.0):\n",
    "    range_linear = [min(Q[key] for key in Q.keys() if key[0] == key[1]), \n",
    "                max(Q[key] for key in Q.keys() if key[0] == key[1])]\n",
    "    range_quadratic = [min(Q[key] for key in Q.keys() if key[0] != key[1]), \n",
    "                   max(Q[key] for key in Q.keys() if key[0] != key[1])]\n",
    "    \n",
    "    scaling_linear = max(range_linear[0]/-1.0, range_linear[1]/1.0)\n",
    "    scaling_quadratic = max(range_quadratic[0]/-1.0, range_quadratic[1]/1.0)\n",
    "    scaling = max(scaling_linear, scaling_quadratic)\n",
    "    return dict((key, factor*Q[key]/scaling) for key in Q.keys())\n",
    "\n",
    "for qpu in qpus:\n",
    "    print(\"Coupler strength range:\", qpus[qpu].properties['extended_j_range'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_reads = 1000\n",
    "t_anneal = 1\n",
    "vg_chain_strength = 1.0\n",
    "scaling = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dwave.system import VirtualGraphComposite\n",
    "\n",
    "samplers = {\"sampler_\" + str(qpu): VirtualGraphComposite(qpus[qpu], \n",
    "            best_embedding[qpu][0], \n",
    "            chain_strength=vg_chain_strength) \n",
    "            for qpu in qpus}\n",
    "\n",
    "samplesets = {}\n",
    "for qpu, sampler in samplers.items():  \n",
    "    samplesets[qpu] = sampler.sample_qubo(scaled_qubo(Q, scaling), \n",
    "                                          num_reads=num_reads, \n",
    "                                          annealing_time=t_anneal, \n",
    "                                          answer_mode='histogram', \n",
    "                                          apply_flux_bias_offsets=True)\n",
    "\n",
    "    partition = [sum(samplesets[qpu].first.sample.values()), graph_nodes - sum(samplesets[qpu].first.sample.values())]\n",
    "    avg_breaks = 100*sum(samplesets[qpu].record.chain_break_fraction)/num_reads\n",
    "    print(\"Partition for {} is {} with lowest energy {:.3f}.\".format(qpu, partition, samplesets[qpu].first.energy))\n",
    "    print(\"Chain breaks for {} is {:.3f} percent.\".format(qpu, avg_breaks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(6, 3*len(samplesets)))\n",
    "axis = 1\n",
    "for qpu, sampler in samplers.items(): \n",
    "    ax = \"ax\"+str(axis)\n",
    "    ax = plt.subplot(len(samplesets)+1, 1, axis)\n",
    "    ax.set_title(\"Sampler: \" + qpu)\n",
    "    ax.set_xlabel(\"Sample\")\n",
    "    ax.set_ylabel(\"Energy\")\n",
    "    ax.plot(range(len(samplesets[qpu])), samplesets[qpu].record.energy, 'bo')\n",
    "    axis += 1\n",
    "\n",
    "lowest = round(0.1*len(samplesets[\"sampler_2000q\"]))\n",
    "ax = \"ax\"+str(axis)\n",
    "ax = plt.subplot(len(samplesets)+1, 1, axis)\n",
    "ax.set_title(\"Delta Energy\")\n",
    "ax.set_xlabel(\"Sample\")\n",
    "ax.set_ylabel(\"Delta Energy\")\n",
    "ax.plot(range(lowest), samplesets[\"sampler_2000q\"].record.energy[0:lowest]-samplesets[\"sampler_advantage\"].record.energy[0:lowest], 'bo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vg_flux_on = samplesets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Direct Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dwave.embedding import embed_qubo\n",
    "embedded_Q = embed_qubo(Q_scaled, best_embedding['2000q'][0], qpus['2000q'].adjacency, chain_strength=1.0)\n",
    "embedded_Q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixed Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_strength = 4000\n",
    "t_anneal = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dwave.system import FixedEmbeddingComposite\n",
    "\n",
    "num_reads = 1000\n",
    "t_anneal = 200\n",
    "\n",
    "samplers = {\"sampler_\" + str(qpu): FixedEmbeddingComposite(qpus[qpu], best_embedding[qpu][0]) \n",
    "            for qpu in qpus}\n",
    "\n",
    "samplesets = {}\n",
    "for qpu, sampler in samplers.items():  \n",
    "    samplesets[qpu] = sampler.sample_qubo(Q, num_reads=num_reads, \n",
    "                                             chain_strength=chain_strength, \n",
    "                                             annealing_time=t_anneal, \n",
    "                                             answer_mode='histogram')\n",
    "\n",
    "    partition = [sum(samplesets[qpu].first.sample.values()), graph_nodes - sum(samplesets[qpu].first.sample.values())]\n",
    "    avg_breaks = 100*sum(samplesets[qpu].record.chain_break_fraction)/num_reads\n",
    "    print(\"Partition for {} is {} with lowest energy {:.3f}.\".format(qpu, partition, samplesets[qpu].first.energy))\n",
    "    print(\"Chain breaks for {} is {:.3f} percent.\".format(qpu, avg_breaks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(6, 3*len(samplesets)))\n",
    "axis = 1\n",
    "for qpu, sampler in samplers.items(): \n",
    "    ax = \"ax\"+str(axis)\n",
    "    ax = plt.subplot(len(samplesets)+1, 1, axis)\n",
    "    ax.set_title(\"Sampler: \" + qpu)\n",
    "    ax.set_xlabel(\"Sample\")\n",
    "    ax.set_ylabel(\"Energy\")\n",
    "    ax.plot(range(len(samplesets[qpu])), samplesets[qpu].record.energy, 'bo')\n",
    "    axis += 1\n",
    "\n",
    "lowest = round(0.1*len(samplesets[\"sampler_2000q\"]))\n",
    "ax = \"ax\"+str(axis)\n",
    "ax = plt.subplot(len(samplesets)+1, 1, axis)\n",
    "ax.set_title(\"Delta Energy\")\n",
    "ax.set_xlabel(\"Sample\")\n",
    "ax.set_ylabel(\"Delta Energy\")\n",
    "ax.plot(range(lowest), samplesets[\"sampler_2000q\"].record.energy[0:lowest]-samplesets[\"sampler_advantage\"].record.energy[0:lowest], 'bo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_strength = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dwave.system import EmbeddingComposite\n",
    "\n",
    "# Import the problem inspector to begin data capture\n",
    "import dwave.inspector\n",
    "\n",
    "num_reads = 1000\n",
    "\n",
    "samplers = {\"sampler_\" + str(qpu): EmbeddingComposite(qpus[qpu]) for qpu in qpus}\n",
    "\n",
    "samplesets = {}\n",
    "for qpu, sampler in samplers.items():  \n",
    "    samplesets[qpu] = sampler.sample_qubo(Q, num_reads=num_reads,\n",
    "                                             answer_mode='raw',\n",
    "                                             chain_strength=chain_strength)\n",
    "    \n",
    "    partition = [sum(samplesets[qpu].first.sample.values()), graph_nodes - sum(samplesets[qpu].first.sample.values())]\n",
    "    avg_breaks = 100*sum(samplesets[qpu].record.chain_break_fraction)/num_reads\n",
    "    print(\"Partition for {} is {} with lowest energy {:.3f}.\".format(qpu, partition, samplesets[qpu].first.energy))\n",
    "    print(\"Chain breaks for {} is {:.3f} percent.\".format(qpu, avg_breaks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(6, 3*len(samplesets)))\n",
    "axis = 1\n",
    "for qpu, sampler in samplers.items(): \n",
    "    ax = \"ax\"+str(axis)\n",
    "    ax = plt.subplot(len(samplesets)+1, 1, axis)\n",
    "    ax.set_title(\"Sampler: \" + qpu)\n",
    "    ax.set_xlabel(\"Sample\")\n",
    "    ax.set_ylabel(\"Energy\")\n",
    "    ax.plot(range(len(samplesets[qpu])), samplesets[qpu].record.energy, 'bo')\n",
    "    axis += 1\n",
    "\n",
    "lowest = round(0.1*len(samplesets[\"sampler_2000q\"]))\n",
    "ax = \"ax\"+str(axis)\n",
    "ax = plt.subplot(len(samplesets)+1, 1, axis)\n",
    "ax.set_title(\"Delta Energy\")\n",
    "ax.set_xlabel(\"Sample\")\n",
    "ax.set_ylabel(\"Delta Energy\")\n",
    "ax.plot(range(lowest), samplesets[\"sampler_2000q\"].record.energy[0:lowest]-samplesets[\"sampler_advantage\"].record.energy[0:lowest], 'bo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hamming Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def get_hamming_distance(x1, x2):    # x1, x2 are NumPy arrays\n",
    "    return np.sum(x1 != x2)\n",
    "\n",
    "def normalized_hamming_distance(sols):\n",
    "    sols = np.array(sols)\n",
    "    hd = np.true_divide(np.array([get_hamming_distance(x1, x2) for x1, x2 in zip(sols, sols[1:])]), np.shape(sols)[1])\n",
    "    return [hd, np.mean(hd)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplesets = {}\n",
    "for qpu, sampler in samplers.items():  \n",
    "    samplesets[qpu] = sampler.sample_qubo(Q, num_reads=num_reads, \n",
    "                                             chain_strength=chain_strength, \n",
    "                                             annealing_time=t_anneal, \n",
    "                                             answer_mode='raw')\n",
    "\n",
    "for sampler in samplers.keys():\n",
    "    print(\"Lowest energy for {} is {:.3f}.\".format(sampler, samplesets[sampler].first.energy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.draw import plot_hamming # To see helper functions, select Jupyter File Explorer View from the Online Learning page\n",
    "\n",
    "hamming_distance = {}\n",
    "for qpu, sampler in samplers.items():  \n",
    "    hamming_distance[qpu] = normalized_hamming_distance(samplesets[qpu].record.sample)\n",
    "\n",
    "print(\"QPU time used: {} microseconds.\".format(sum(samplesets[qpu].info['timing']['qpu_access_time'] for qpu in samplers)))\n",
    "plot_hamming(hamming_distance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BEST SUBMISSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(x for x in Q.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VERIFY QUBO\n",
    "from dwave.system import EmbeddingComposite\n",
    "\n",
    "chain_strength = 1000\n",
    "num_reads = 1000\n",
    "\n",
    "samplers = {\"sampler_\" + str(qpu): EmbeddingComposite(qpus[qpu]) for qpu in qpus}\n",
    "\n",
    "samplesets = {}\n",
    "for qpu, sampler in samplers.items():  \n",
    "    samplesets[qpu] = sampler.sample_qubo(Q, num_reads=num_reads, \n",
    "                                             chain_strength=chain_strength)\n",
    "    \n",
    "    partition = [sum(samplesets[qpu].first.sample.values()), graph_nodes - sum(samplesets[qpu].first.sample.values())]\n",
    "    avg_breaks = 100*sum(samplesets[qpu].record.chain_break_fraction)/num_reads\n",
    "    print(\"Partition for {} is {} with lowest energy {:.3f}.\".format(qpu, partition, samplesets[qpu].first.energy))\n",
    "    print(\"Chain breaks for {} is {:.3f} percent.\".format(qpu, avg_breaks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dimod\n",
    "(h, J, offset) = dimod.qubo_to_ising(Q)\n",
    "\n",
    "range_h = [min(h[key] for key in h.keys()), \n",
    "               max(h[key] for key in h.keys())]\n",
    "range_J = [min(J[key] for key in J.keys()), \n",
    "               max(J[key] for key in J.keys())]\n",
    "\n",
    "print(\"Range h {}\".format(range_h))\n",
    "print(\"Range J {}\".format(range_J))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUBO --> ISING\n",
    "samplers = {\"sampler_\" + str(qpu): EmbeddingComposite(qpus[qpu]) for qpu in qpus}\n",
    "\n",
    "samplesets = {}\n",
    "for qpu, sampler in samplers.items():  \n",
    "    samplesets[qpu] = sampler.sample_ising(h, J, \n",
    "                                           num_reads=num_reads, \n",
    "                                           auto_scale=True,\n",
    "                                           chain_strength=4000)\n",
    "    \n",
    "    partition_miss = sum(samplesets[qpu].first.sample.values())\n",
    "    avg_breaks = 100*sum(samplesets[qpu].record.chain_break_fraction)/num_reads\n",
    "    print(\"Partition miss for {} is {} with lowest energy {:.3f}.\".format(qpu, partition_miss, samplesets[qpu].first.energy))\n",
    "    print(\"Chain breaks for {} is {:.3f} percent.\".format(qpu, avg_breaks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_ising(h, J, factor=1.0):\n",
    "    range_h = [min(h[key] for key in h.keys()), \n",
    "               max(h[key] for key in h.keys())]\n",
    "    range_J = [min(J[key] for key in J.keys()), \n",
    "               max(J[key] for key in J.keys())]\n",
    "    \n",
    "    scaling_h = max(range_h[0]/-1.0, range_h[1]/1.0)\n",
    "    scaling_J = max(range_J[0]/-1.0, range_J[1]/1.0)\n",
    "    scaling = max(scaling_h, scaling_J)\n",
    "    return dict((key, factor*h[key]/scaling) for key in h.keys()), dict((key, factor*J[key]/scaling) for key in J.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_scaled, J_scaled =  scaled_ising(h, J, factor=0.1)\n",
    "\n",
    "range_hs = [min(h_scaled[key] for key in h_scaled.keys()), \n",
    "               max(h_scaled[key] for key in h_scaled.keys())]\n",
    "range_Js = [min(J_scaled[key] for key in J_scaled.keys()), \n",
    "               max(J_scaled[key] for key in J_scaled.keys())]\n",
    "\n",
    "print(\"Range h {}\".format(range_hs))\n",
    "print(\"Range J {}\".format(range_Js))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dwave.embedding import embed_ising\n",
    "\n",
    "chain_strength_scaled = 2.\n",
    "\n",
    "embedded_vals = {}\n",
    "for qpu in qpus: \n",
    "    embedded_vals[qpu] = embed_ising(h_scaled, \n",
    "                                          J_scaled, \n",
    "                                          best_embedding[qpu][0], \n",
    "                                          qpus[qpu].adjacency, \n",
    "                                          chain_strength=chain_strength_scaled)\n",
    "    \n",
    "    print(\"{} J: {}\".format(qpu, sorted(set(embedded_vals[qpu][1][key] \n",
    "                            for key in embedded_vals[qpu][1].keys()))))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 8))\n",
    "axis = 1\n",
    "for qpu_name, qpu in qpus.items(): \n",
    "    ax = \"ax\"+str(axis)\n",
    "    ax = plt.subplot(2, 1, axis)\n",
    "    ax.set_title(\"Sampler: \" + qpu_name)\n",
    "    ax.set_xlabel(\"--\")\n",
    "    ax.set_ylabel(\"J\")\n",
    "    ax.plot(range(len(embedded_vals[qpu_name][1])), embedded_vals[qpu_name][1].values(), 'bo')\n",
    "    axis += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dwave.embedding import unembed_sampleset, chain_break_frequency\n",
    "\n",
    "num_reads = 5000\n",
    "\n",
    "samplesets_embedded = {}\n",
    "samplesets = {}\n",
    "chain_breaks = {}\n",
    "\n",
    "for qpu in qpus:  \n",
    "    samplesets_embedded[qpu] = qpus[qpu].sample_ising(embedded_vals[qpu][0], \n",
    "                                           embedded_vals[qpu][1], \n",
    "                                           num_reads=num_reads,\n",
    "                                           answer_mode='histogram',\n",
    "                                           auto_scale=False)\n",
    "    samplesets[qpu] = unembed_sampleset(target_sampleset=samplesets_embedded[qpu], \n",
    "                                        embedding=best_embedding[qpu][0], \n",
    "                                        source_bqm=dimod.BinaryQuadraticModel.from_ising(h, J), \n",
    "                                        chain_break_method=None, \n",
    "                                        chain_break_fraction=True, \n",
    "                                        return_embedding=True)\n",
    "    \n",
    "    partition_miss = sum(samplesets[qpu].first.sample.values())\n",
    "    print(\"Partition miss for {} is {} with lowest energy {:.3f}.\".format(qpu, partition_miss, samplesets[qpu].first.energy))\n",
    "\n",
    "    chain_breaks[qpu] = chain_break_frequency(samplesets_embedded[qpu], \n",
    "                                                          best_embedding[qpu][0])\n",
    "    print(qpu, \":\", {key:100*val for key, val in chain_breaks[qpu].items()})            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplesets[\"advantage\"].record.chain_break_fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, absolute_import\n",
    "\n",
    "import dimod\n",
    "import numpy as np\n",
    "\n",
    "from six import iteritems\n",
    "\n",
    "from dwave.embedding.chain_breaks import broken_chains\n",
    "\n",
    "\n",
    "def my_chain_break_frequency(samples_like, embedding):\n",
    "    \"\"\"Determine the frequency of chain breaks in the given samples.\n",
    "\n",
    "    Args:\n",
    "        samples_like (samples_like/:obj:`dimod.SampleSet`):\n",
    "            A collection of raw samples. 'samples_like' is an extension of NumPy's array_like.\n",
    "            See :func:`dimod.as_samples`.\n",
    "\n",
    "        embedding (dict):\n",
    "            Mapping from source graph to target graph as a dict of form {s: {t, ...}, ...},\n",
    "            where s is a source-model variable and t is a target-model variable.\n",
    "\n",
    "    Returns:\n",
    "        dict: Frequency of chain breaks as a dict in the form {s: f, ...},  where s\n",
    "        is a variable in the source graph and float f the fraction\n",
    "        of broken chains.\n",
    "\n",
    "    Examples:\n",
    "        This example embeds a single source node, 'a', as a chain of two target nodes (0, 1)\n",
    "        and uses :func:`.chain_break_frequency` to show that out of two synthetic samples,\n",
    "        one ([-1, +1]) represents a broken chain.\n",
    "\n",
    "        >>> import numpy as np\n",
    "        ...\n",
    "        >>> samples = np.array([[-1, +1], [+1, +1]])\n",
    "        >>> embedding = {'a': {0, 1}}\n",
    "        >>> print(dwave.embedding.chain_break_frequency(samples, embedding)['a'])\n",
    "        0.5\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    if isinstance(samples_like, dimod.SampleSet):\n",
    "        labels = samples_like.variables\n",
    "        samples = samples_like.record.sample\n",
    "        num_occurrences = samples_like.record.num_occurrences\n",
    "    else:\n",
    "        samples, labels = dimod.as_samples(samples_like)\n",
    "        num_occurrences = np.ones(samples.shape[0])\n",
    "\n",
    "    if not all(v == idx for idx, v in enumerate(labels)):\n",
    "        labels_to_idx = {v: idx for idx, v in enumerate(labels)}\n",
    "        embedding = {v: {labels_to_idx[u] for u in chain} for v, chain in embedding.items()}\n",
    "\n",
    "    if not embedding:\n",
    "        return {}\n",
    "\n",
    "    variables, chains = zip(*embedding.items())\n",
    "\n",
    "    broken = broken_chains(samples, chains)\n",
    "\n",
    "    return {v: float(np.average(broken[:, cidx], weights=num_occurrences))\n",
    "            for cidx, v in enumerate(variables)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright &copy; D-Wave Systems Inc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": "1",
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "229px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
